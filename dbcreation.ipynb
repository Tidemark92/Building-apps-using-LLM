{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d77d2c13-457f-4a59-8ce4-39a3450fd429",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d0f6942-b984-4f73-ade9-60c1e8c0a484",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a database connection\n",
    "conn = sqlite3.connect('LLM.db')\n",
    "\n",
    "#create a cursor object to excute sql commands\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fb4ccbc-ecc1-45a5-b917-e0127eae9e1c",
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "table 'stockTable' already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#create \"stokcTable\" table\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mcur\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'''\u001b[39;49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;43mCREATE TABLE \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstockTable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m (\u001b[39;49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;43m    ticker TEXT DEFAULT NULL,\u001b[39;49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;43m    created_at DATETIME DEFAULT NULL,\u001b[39;49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;43m    open REAL DEFAULT NULL,\u001b[39;49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;43m    high REAL DEFAULT NULL,\u001b[39;49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;43m    low REAL DEFAUL NULL,\u001b[39;49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;43m    close REAL DEFAULT NULL,\u001b[39;49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;43m    volume INTEGER DEFAULT NULL\u001b[39;49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;43m)\u001b[39;49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;43m'''\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOperationalError\u001b[0m: table 'stockTable' already exists"
     ]
    }
   ],
   "source": [
    "#create \"stokcTable\" table\n",
    "cur.execute('''\n",
    "CREATE TABLE 'stockTable' (\n",
    "    ticker TEXT DEFAULT NULL,\n",
    "    created_at DATETIME DEFAULT NULL,\n",
    "    open REAL DEFAULT NULL,\n",
    "    high REAL DEFAULT NULL,\n",
    "    low REAL DEFAUL NULL,\n",
    "    close REAL DEFAULT NULL,\n",
    "    volume INTEGER DEFAULT NULL\n",
    ")\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "eeaa046c-6ad7-4aff-98a3-1773d225f58b",
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "table newsSentiment already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[101], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#create newssentiment table\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mcur\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'''\u001b[39;49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;43mCREATE TABLE newsSentiment(\u001b[39;49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;43m    title TEXT,\u001b[39;49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;43m    url TEXT,\u001b[39;49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;43m    time_published DATETIME,\u001b[39;49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;43m    authors TEXT,\u001b[39;49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;43m    summary TEXT,\u001b[39;49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;43m    banner_image TEXT,\u001b[39;49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;43m    source TEXT,\u001b[39;49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;43m    category_within_source TEXT,\u001b[39;49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;43m    source_domain TEXT\u001b[39;49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124;43m    topic TEXT,\u001b[39;49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;43m    topic_relevance_score TEXT,\u001b[39;49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;43m    overall_sentiment_score REAL,\u001b[39;49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;43m    overall_sentiment_label TEXT\u001b[39;49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;43m)\u001b[39;49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;43m'''\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOperationalError\u001b[0m: table newsSentiment already exists"
     ]
    }
   ],
   "source": [
    "#create newssentiment table\n",
    "\n",
    "cur.execute('''\n",
    "CREATE TABLE newsSentiment(\n",
    "    title TEXT,\n",
    "    url TEXT,\n",
    "    time_published DATETIME,\n",
    "    authors TEXT,\n",
    "    summary TEXT,\n",
    "    banner_image TEXT,\n",
    "    source TEXT,\n",
    "    category_within_source TEXT,\n",
    "    source_domain TEXT\n",
    "    topic TEXT,\n",
    "    topic_relevance_score TEXT,\n",
    "    overall_sentiment_score REAL,\n",
    "    overall_sentiment_label TEXT\n",
    ")\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "eec90b68-e85e-48e9-bc94-926dd99d8aaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x13a017040>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create companyinfo table\n",
    "\n",
    "cur.execute('''\n",
    "CREATE TABLE companyinfo(\n",
    "ticker TEXT PRIMARY KEY,\n",
    "AssetType TEXT,\n",
    "Name TEXT,\n",
    "Description TEXT,\n",
    "CIK TEXT,\n",
    "Exchange TEXT,\n",
    "Currency TEXT,\n",
    "Country TEXT,\n",
    "Sector TEXT,\n",
    "Industry TEXT,\n",
    "Address TEXT,\n",
    "FiscalYearEnd TEXT,\n",
    "LatestQuarter DATE,\n",
    "MarketCapitalization INTEGER,\n",
    "EBITDA INTEGER,\n",
    "PERatio REAL,\n",
    "PEGRatio REAL,\n",
    "BookValue REAL,\n",
    "DividendPerShare REAL,\n",
    "DividendYield REAL,\n",
    "EPS REAL,\n",
    "RevenuePerShareTTM REAL,\n",
    "ProfitMargin REAL,\n",
    "OperatingMarginTTM REAL,\n",
    "ReturnOnAssetsTTM REAL,\n",
    "ReturnOnEquityTTM REAL,\n",
    "RevenueTTM INTEGER,\n",
    "GrossProfitTTM INTEGER,\n",
    "DilutedEPSTTM REAL,\n",
    "QuarterlyEarningsGrowthYOY REAL,\n",
    "QuarterlyRevenueGrowthYOY REAL,\n",
    "AnalystTargetPrice REAL,\n",
    "TrailingPE REAL,\n",
    "ForwardPE REAL,\n",
    "PriceToSalesRatioTTM REAL,\n",
    "PriceToBookRatio REAL,\n",
    "EVToRevenue REAL,\n",
    "EVToEBITDA REAL,\n",
    "Beta REAL,\n",
    "\"52WeekHigh\" REAL,\n",
    "\"52WeekLow\" REAL,\n",
    "\"50DayMovingAverage\" REAL,\n",
    "\"200DayMovingAverage\" REAL,\n",
    "SharesOutstanding INTEGER,\n",
    "DividendDate DATE,\n",
    "ExDividendDate DATE\n",
    ")\n",
    "'''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "2fae9a04-aedf-4cff-8557-97693e261700",
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "table embeddings already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[115], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#create embeddings table\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mcur\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'''\u001b[39;49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;43mCREATE TABLE embeddings (\u001b[39;49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;43m    id INTEGER PRIMARY KEY AUTOINCREMENT,\u001b[39;49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;43m    category TEXT,\u001b[39;49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;43m    question TEXT,\u001b[39;49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;43m    question_embedding BLOB,\u001b[39;49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;43m    answer TEXT,\u001b[39;49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;43m    answer_embedding BLOB,\u001b[39;49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;43m    created_at DATETIME DEFAULT CURRENT_TIMESTAMP\u001b[39;49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;43m)\u001b[39;49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;43m'''\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOperationalError\u001b[0m: table embeddings already exists"
     ]
    }
   ],
   "source": [
    "#create embeddings table\n",
    "\n",
    "cur.execute('''\n",
    "CREATE TABLE embeddings (\n",
    "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    category TEXT,\n",
    "    question TEXT,\n",
    "    question_embedding BLOB,\n",
    "    answer TEXT,\n",
    "    answer_embedding BLOB,\n",
    "    created_at DATETIME DEFAULT CURRENT_TIMESTAMP\n",
    ")\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d95a3326-31b2-4c89-8bba-d9ca00d9b836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x1076a01c0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.execute('''\n",
    "SELECT name FROM sqlite_master WHERE type='table';\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb11e55e-c6df-4d19-b79c-4c891370811d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stockTable\n",
      "newsSentiment\n",
      "embeddings\n",
      "sqlite_sequence\n",
      "companyinfo\n"
     ]
    }
   ],
   "source": [
    "tables = cur.fetchall()\n",
    "for table in tables:\n",
    "    print(table[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fc40c8f-1372-4821-9b06-7eeb6a805ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9f203dd-46e8-4052-9de7-5ff4dab994cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import datetime\n",
    "import getpass\n",
    "import numpy as np\n",
    "import openai\n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8379115e-bc21-4d54-990c-c7d4c4b0864b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from langchain.sql_database import SQLDatabase\n",
    "#from langchain.llms.openai import OpenAI\n",
    "from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
    "from langchain.agents import create_sql_agent\n",
    "#from openai.embeddings_utils import get_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5cd3aeb-e2bd-4a2d-ba0d-22148fe1ec63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the get_embeddings functions\n",
    "\n",
    "def get_embeddings(text, model=\"text-embedding-3-small\"):\n",
    "    text = text.repalce(\"\\n\", \"\")\n",
    "    return llm.embeddings.create(input = [text], model=model).data[0].emdedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b78d5b22-679e-4a38-8331-b6c730f62868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "enter alphavantage apikey here ········\n",
      "enter openai apikey here ········\n",
      "enter elevenlabs apikey here ········\n"
     ]
    }
   ],
   "source": [
    "#set api keys\n",
    "\n",
    "alpha_vantage_apikey = getpass.getpass(\"enter alphavantage apikey here\")\n",
    "openai_apikey = getpass.getpass(\"enter openai apikey here\")\n",
    "elevenlabs_apikey = getpass.getpass(\"enter elevenlabs apikey here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8399ec5-9910-4586-b2ce-9db43f7830a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up the connection to some data store and the ticker list\n",
    "ticker_list=['TSLA', 'AMZN', 'PLTR']\n",
    "conn = sqlite3.connect('LLM.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1784c325-1e7e-4109-89a5-3f0105663129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2024-06', '2024-05']\n"
     ]
    }
   ],
   "source": [
    "def get_past_months(num_months):\n",
    "    today = datetime.today()\n",
    "    months = []\n",
    "\n",
    "    for months_ago in range(0, num_months):\n",
    "        target_date = today - relativedelta(months=months_ago)\n",
    "        months.append(target_date.strftime('%Y-%m'))\n",
    "\n",
    "    return months\n",
    "\n",
    "#set the number of months\n",
    "\n",
    "num_months = 2\n",
    "year_month_list = get_past_months(num_months)\n",
    "print(year_month_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8b5c3b13-67db-4664-a702-414f070a4227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TSLA\n",
      "2024-06\n"
     ]
    },
    {
     "ename": "ProgrammingError",
     "evalue": "Cannot operate on a closed database.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 60\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 60\u001b[0m     cur \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcursor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m     cur\u001b[38;5;241m.\u001b[39mexecute(stmt, params)\n",
      "\u001b[0;31mProgrammingError\u001b[0m: Cannot operate on a closed database.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 63\u001b[0m\n\u001b[1;32m     61\u001b[0m     cur\u001b[38;5;241m.\u001b[39mexecute(stmt, params)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m---> 63\u001b[0m     \u001b[43mcur\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m#required to not hit api limits\u001b[39;00m\n",
      "\u001b[0;31mProgrammingError\u001b[0m: Cannot operate on a closed database."
     ]
    }
   ],
   "source": [
    "#pull intraday info for each stock and store it into some database\n",
    "\n",
    "for ticker in ticker_list:\n",
    "    print(ticker)\n",
    "    data_list = []\n",
    "    for year_month in year_month_list:\n",
    "        print(year_month)\n",
    "\n",
    "        intraday_price_url = \"https://www.alphavantage.co/query?function=TIME_SERIES_INTRADAY&symbol={}&interval=5min&month={}outputsize=full&apikey={}\".format(ticker, year_month, alpha_vantage_apikey)\n",
    "\n",
    "        r = requests.get(intraday_price_url)\n",
    "\n",
    "        try:\n",
    "            data = r.json()['Time Series (5min)']\n",
    "        except:\n",
    "            time.sleep(1)\n",
    "            continue\n",
    "\n",
    "        for key in data:\n",
    "            document = data[key]\n",
    "            document['datetime'] = key\n",
    "            document['ticker'] = ticker\n",
    "\n",
    "            document['open'] = document['1. open']\n",
    "            document['high'] = document['2. high']\n",
    "            document['low'] = document['3. low']\n",
    "            document['close'] = document['4. close']\n",
    "            document['volume'] = document['5. volume']\n",
    "\n",
    "            document['open'] = float(document['open'])\n",
    "            document['high'] = float(document['high'])\n",
    "            document['low'] = float(document['low'])\n",
    "            document['close'] = float(document['close'])\n",
    "            document['volume'] = int(document['volume'])\n",
    "\n",
    "            del document['1. open']\n",
    "            del document['2. high']\n",
    "            del document['3. low']\n",
    "            del document['4. close']\n",
    "            del document['5. volume']\n",
    "\n",
    "            data_list += [document]\n",
    "\n",
    "            #inside the loop, create the params dictionary with the correct values\n",
    "            params = {\n",
    "                'datetime': document['datetime'],\n",
    "                'ticker': ticker,\n",
    "                'open': document['open'],\n",
    "                'high': document['high'],\n",
    "                'low': document['low'],\n",
    "                'close': document['close'],\n",
    "                'volume': document['volume']\n",
    "            }\n",
    "\n",
    "            #construct and execute the sql statement\n",
    "            table_name = 'stockTable'\n",
    "            stmt = f\"INSERT INTO {table_name} (created_at, ticker, open, high, low, close, volume) VALUES (:datetime, :ticker, :open, :high, :low, :close, :volume)\"\n",
    "\n",
    "            try:\n",
    "                cur = conn.cursor()\n",
    "                cur.execute(stmt, params)\n",
    "            finally:\n",
    "                cur.close()\n",
    "\n",
    "            time.sleep(1) #required to not hit api limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21022171-ccd2-4452-8511-46cebe640d95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x122f4b4c0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn = sqlite3.connect('LLM.db')\n",
    "cur = conn.cursor()\n",
    "cur.execute('''\n",
    "SELECT COUNT(*) FROM stockTable\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5be038dd-75ed-4097-b4b0-0bbfb418a665",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47bcab29-732a-478d-b11c-5a8facce3fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TSLA\n",
      "AMZN\n",
      "PLTR\n"
     ]
    }
   ],
   "source": [
    "#bring in company data\n",
    "\n",
    "#pull intraday data for each stock and write to LLM.db\n",
    "\n",
    "for ticker in ticker_list:\n",
    "    print(ticker)\n",
    "    data_list = []\n",
    "\n",
    "    company_overview = \"https://www.alphavantage.co/query?function=OVERVIEW&symbol={}&outputsize=full&apikey={}\".format(ticker, alpha_vantage_apikey)\n",
    "    r = requests.get(company_overview)\n",
    "\n",
    "    try:\n",
    "        data = r.json()\n",
    "    except:\n",
    "        time.sleep(3)\n",
    "        continue\n",
    "\n",
    "    data['CIK'] = int(data['CIK'])\n",
    "    data['MarketCapitalization'] = float(data['MarketCapitalization'])\n",
    "    \n",
    "    #assume data['EBITDA'] is a string containing 'None'\n",
    "    ebitda_str = data['EBITDA']\n",
    "\n",
    "    #handle the case where EBITDA is 'None'\n",
    "    if ebitda_str.lower() == 'none':\n",
    "        data['EBITDA'] = 0.0\n",
    "    else:\n",
    "        data['EBITDA'] = float(ebitda_str)\n",
    "\n",
    "    PERatio_flt = data['PERatio']\n",
    "\n",
    "    #handle the case where data['PERatio'] is '-'\n",
    "    if PERatio_flt == '-':\n",
    "        data['PERatio'] = 0.0\n",
    "    else:\n",
    "        data['PERatio'] = float(PERatio_flt)\n",
    "\n",
    "    data['PEGRatio'] = float(data['PEGRatio'])\n",
    "    data['BookValue'] = float(data['BookValue'])\n",
    "\n",
    "    #assume data['DividendPerShare'] is a string containing 'None'\n",
    "    dividend_per_share_str = data['DividendPerShare']\n",
    "    if dividend_per_share_str.lower() == 'none':\n",
    "        data['DividendPerShare'] = 0.0\n",
    "    else:\n",
    "        data['DividendPerShare'] = float(dividend_per_share_str)\n",
    "    #data['DividendPerShare'] = float(data['DividendPerShare'])\n",
    "    \n",
    "    #assume data['DividendYield'] is a string containing 'None'\n",
    "    dividend_yield_str = data['DividendYield']\n",
    "    if dividend_yield_str.lower() == 'none':\n",
    "        data['DividendYield'] = 0.0\n",
    "    else:\n",
    "        data['DividendYield'] = float(dividend_yield)\n",
    "    #data['DividendYield'] = float(data['DividendYield'])\n",
    "    \n",
    "    data['EPS'] = float(data['EPS'])\n",
    "    data['RevenuePerShareTTM'] = float(data['RevenuePerShareTTM'])\n",
    "    data['ProfitMargin'] = float(data['ProfitMargin'])\n",
    "    data['OperatingMarginTTM'] = float(data['OperatingMarginTTM'])\n",
    "    data['ReturnOnEquityTTM'] = float(data['ReturnOnEquityTTM'])\n",
    "    data['ReturnOnAssetsTTM'] = float(data['ReturnOnAssetsTTM'])\n",
    "    data['RevenueTTM'] = int(data['RevenueTTM'])\n",
    "    data['GrossProfitTTM'] = int(data['GrossProfitTTM'])\n",
    "    data['DilutedEPSTTM'] = float(data['DilutedEPSTTM'])\n",
    "    data['QuarterlyEarningsGrowthYOY'] = float(data['QuarterlyEarningsGrowthYOY'])\n",
    "    data['QuarterlyRevenueGrowthYOY'] = float(data['QuarterlyRevenueGrowthYOY'])\n",
    "    data['AnalystTargetPrice'] = float(data['AnalystTargetPrice'])\n",
    "\n",
    "    #assuming data['TrailingPE'] is a string containing '-'\n",
    "    trailing_pe_str = data['TrailingPE']\n",
    "    if trailing_pe_str == '-':\n",
    "        data['TrailingPE'] = 0.0\n",
    "    else:\n",
    "        try:\n",
    "            data['TrailingPE'] = float(trailing_pe_str)\n",
    "        except ValueError:\n",
    "            data['TrailingPE'] = 0.0\n",
    "\n",
    "    data['ForwardPE'] = float(data['ForwardPE'])\n",
    "    data['PriceToSalesRatioTTM'] = float(data['PriceToSalesRatioTTM'])\n",
    "\n",
    "    #assume that data['PriceToBookRatio'] is a string containing '-'\n",
    "    price_to_book_ratio_flt = data['PriceToBookRatio']\n",
    "    if price_to_book_ratio_flt == '-':\n",
    "        data['PriceToBookRatio'] = 0.0\n",
    "    else:\n",
    "        data['PriceToBookRatio'] = float(price_to_book_ratio_flt)\n",
    "\n",
    "    #assume that data['EVToRevenue'] is a string containing '-'\n",
    "    ev_to_revenue_str = data['EVToRevenue']\n",
    "    if ev_to_revenue_str == '-':\n",
    "        data['EVToRevenue'] = 0.0\n",
    "    else:\n",
    "        data['EVToRevenue'] = float(ev_to_revenue_str)\n",
    "\n",
    "    #assume data['EVToEBITDA'] is a string containing '-'\n",
    "    ev_to_ebitda_str = data['EVToEBITDA']\n",
    "    if ev_to_ebitda_str == '-':\n",
    "        data['EVToEBITDA'] = 0.0\n",
    "    else:\n",
    "        data['EVToEBITDA'] = float(ev_to_ebitda_str)\n",
    "\n",
    "    data['Beta'] = float(data['Beta'])\n",
    "    data['52WeekHigh'] = float(data['52WeekHigh'])\n",
    "    data['52WeekLow'] = float(data['52WeekLow'])\n",
    "    data['50DayMovingAverage'] = float(data['50DayMovingAverage'])\n",
    "    data['200DayMovingAverage'] = float(data['200DayMovingAverage'])\n",
    "    data['SharesOutstanding'] = int(data['SharesOutstanding'])\n",
    "\n",
    "    #assume that data['DividendDate'] is a date possible to be 'None'\n",
    "    dividend_date_str = data['DividendDate']\n",
    "    if dividend_date_str == 'None':\n",
    "        data['DividendDate'] = '9999-12-31'\n",
    "    else:\n",
    "        data['DividendDate'] = str(dividend_date_str)\n",
    "\n",
    "    #assume that data['ExDividendDate'] is a date possible to be 'None'\n",
    "    ex_dividend_date_str = data['ExDividendDate']\n",
    "    if ex_dividend_date_str == 'None':\n",
    "        data['ExDividendDate'] = '9999-12-31'\n",
    "    else:\n",
    "        data['ExDividendDate'] = str(data['ExDividendDate'])\n",
    "\n",
    "    data_list += [data]\n",
    "\n",
    "    #inside the loop, create the params dictionary with the correct values\n",
    "    params = {\n",
    "                'Symbol': data['Symbol'],\n",
    "                'AssetType': data['AssetType'],\n",
    "                'Name': data['Name'],\n",
    "                'Description': data['Description'],\n",
    "                'CIK': data['CIK'],\n",
    "                'Exchange': data['Exchange'],\n",
    "                'Currency': data['Currency'],\n",
    "                'Country': data['Country'],\n",
    "                'Sector': data['Sector'],\n",
    "                'Industry': data['Industry'],\n",
    "                'Address': data['Address'],\n",
    "                'FiscalYearEnd': data['FiscalYearEnd'],\n",
    "                'LatestQuarter': data['LatestQuarter'],\n",
    "                'MarketCapitalization': data['MarketCapitalization'],\n",
    "                'EBITDA': data['EBITDA'],\n",
    "                'PERatio': data['PERatio'],\n",
    "                'PEGRatio': data['PEGRatio'],\n",
    "                'BookValue': data['BookValue'],\n",
    "                'DividendPerShare': data['DividendPerShare'],\n",
    "                'DividendYield': data['DividendYield'],\n",
    "                'EPS': data['EPS'],\n",
    "                'RevenuePerShareTTM': data['RevenuePerShareTTM'],\n",
    "                'ProfitMargin': data['ProfitMargin'],\n",
    "                'OperatingMarginTTM': data['OperatingMarginTTM'],\n",
    "                'ReturnOnAssetsTTM': data['ReturnOnAssetsTTM'],\n",
    "                'ReturnOnEquityTTM': data['ReturnOnEquityTTM'],\n",
    "                'RevenueTTM': data['RevenueTTM'],\n",
    "                'GrossProfitTTM': data['GrossProfitTTM'],\n",
    "                'DilutedEPSTTM': data['DilutedEPSTTM'],\n",
    "                'QuarterlyEarningsGrowthYOY': data['QuarterlyEarningsGrowthYOY'],\n",
    "                'QuarterlyRevenueGrowthYOY': data['QuarterlyRevenueGrowthYOY'],\n",
    "                'AnalystTargetPrice': data['AnalystTargetPrice'],\n",
    "                'TrailingPE': data['TrailingPE'],\n",
    "                'ForwardPE': data['ForwardPE'],\n",
    "                'PriceToSalesRatioTTM': data['PriceToSalesRatioTTM'],\n",
    "                'PriceToBookRatio': data['PriceToBookRatio'],\n",
    "                'EVToRevenue': data['EVToRevenue'],\n",
    "                'EVToEBITDA': data['EVToEBITDA'],\n",
    "                'Beta': data['Beta'],\n",
    "                '52WeekHigh': data['52WeekHigh'],\n",
    "                '52WeekLow': data['52WeekLow'],\n",
    "                '50DayMovingAverage': data['50DayMovingAverage'],\n",
    "                '200DayMovingAverage': data['200DayMovingAverage'],\n",
    "                'SharesOutstanding': data['SharesOutstanding'],\n",
    "                'DividendDate': data['DividendDate'],\n",
    "                'ExDividendDate': data['ExDividendDate']\n",
    "    }\n",
    "\n",
    "    #construct and execute the sql statement\n",
    "    table_name = 'companyinfo'\n",
    "    stmt = f\"INSERT INTO {table_name} (ticker, AssetType, Name, Description, CIK, Exchange, Currency, Country, Sector, Industry, Address, FiscalYearEnd, LatestQuarter, MarketCapitalization, EBITDA, PERatio, PEGRatio, BookValue, DividendPerShare, DividendYield, EPS, RevenuePerShareTTM, ProfitMargin, OperatingMarginTTM, ReturnOnAssetsTTM, ReturnOnEquityTTM, RevenueTTM, GrossProfitTTM, DilutedEPSTTM, QuarterlyEarningsGrowthYOY, QuarterlyRevenueGrowthYOY, AnalystTargetPrice, TrailingPE, ForwardPE, PriceToSalesRatioTTM, PriceToBookRatio, EVToRevenue, EVToEBITDA, Beta, '52WeekHigh', '52WeekLow', '50DayMovingAverage', '200DayMovingAverage', SharesOutstanding, DividendDate, ExDividendDate) VALUES (:Symbol, :AssetType, :Name, :Description, :CIK, :Exchange, :Currency, :Country, :Sector, :Industry, :Address, :FiscalYearEnd, :LatestQuarter, :MarketCapitalization, :EBITDA, :PERatio, :PEGRatio, :BookValue, :DividendPerShare, :DividendYield, :EPS, :RevenuePerShareTTM, :ProfitMargin, :OperatingMarginTTM, :ReturnOnAssetsTTM, :ReturnOnEquityTTM, :RevenueTTM, :GrossProfitTTM, :DilutedEPSTTM, :QuarterlyEarningsGrowthYOY, :QuarterlyRevenueGrowthYOY, :AnalystTargetPrice, :TrailingPE, :ForwardPE, :PriceToSalesRatioTTM, :PriceToBookRatio, :EVToRevenue, :EVToEBITDA, :Beta, :52WeekHigh, :52WeekLow, :50DayMovingAverage, :200DayMovingAverage, :SharesOutstanding, :DividendDate, :ExDividendDate)\"\n",
    "\n",
    "    try:\n",
    "        conn = sqlite3.connect('LLM.db')\n",
    "        cur = conn.cursor()\n",
    "        cur.execute(stmt, params)\n",
    "    finally:\n",
    "        cur.close()\n",
    "        conn.close()\n",
    "\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "df6b22ec-1026-4cae-8df2-9cdbc8413796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TSLA\n",
      "2024-06-01 00:00:00\n",
      "2024-05-01 00:00:00\n",
      "AMZN\n",
      "2024-06-01 00:00:00\n",
      "2024-05-01 00:00:00\n",
      "PLTR\n",
      "2024-06-01 00:00:00\n",
      "2024-05-01 00:00:00\n"
     ]
    }
   ],
   "source": [
    "#bring in news sentiment\n",
    "\n",
    "for ticker in ticker_list:\n",
    "    print(ticker)\n",
    "    data_list = []\n",
    "\n",
    "    for i in year_month_list:\n",
    "        date_object = datetime.strptime(i, '%Y-%m')\n",
    "        print(date_object)\n",
    "        output_date = date_object.strftime('%Y%m%d') + \"T0000\"\n",
    "\n",
    "        #get next month from the 'date_object'\n",
    "        previous_month_date = date_object + relativedelta(months = -1)\n",
    "        previous_month_date = previous_month_date.strftime('%Y%m%d')+\"T0000\"\n",
    "\n",
    "        #update 'date_object' for the next iteration\n",
    "        date_object = previous_month_date\n",
    "\n",
    "        #grab info about news sentiment from Alpha Vantage\n",
    "        news_and_sentiment = 'https://www.alphavantage.co/query?function=NEWS_SENTIMENT&tickers={}&time_to={}limit=100&outputsize=full&apikey={}'.format(ticker, previous_month_date, output_date, alpha_vantage_apikey)\n",
    "        r = requests.get(news_and_sentiment)\n",
    "\n",
    "        try:\n",
    "            data = r.json()\n",
    "            feed = data['Feed']\n",
    "        except:\n",
    "            time.sleep(1)\n",
    "            continue\n",
    "\n",
    "        for item in feed:\n",
    "            item['title'] = str(item['title'])\n",
    "            item['url'] = str(item['url'])\n",
    "            item['time_published'] = datetiem.datetime.strptime(str(item['time_published']), '%Y%m%dT%H%M%S').strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "            #check if item['authors'] is empty\n",
    "            if item['authors']:\n",
    "                authors_str = str(item['authors'][0])\n",
    "            else:\n",
    "                authors_str = 'No authors available'\n",
    "\n",
    "            item['authors'] = authors_str\n",
    "\n",
    "            item['summary'] = str(item['summary'])\n",
    "            item['banner_image'] = str(item['banner_image'])\n",
    "            item['source'] = str(item['source'])\n",
    "            item['category_within_source'] = str(item['category_within_source'])\n",
    "            item['source_domain'] = str(item['source_domain'])\n",
    "            item['topic'] = str(item['topics'][0][\"topic\"])\n",
    "            item['topic_relevance_score'] = float(item['topics'][0]['relevance_score'])\n",
    "            item['overall_sentiment_score'] = float(item['overall_sentiment_score'])\n",
    "            item['overall_sentiment_label'] = str(item['overall_sentiment_label'])\n",
    "            item['ticker'] = str(item['ticker_sentiment'][0]['ticker'])\n",
    "            item['ticker_relevance_score'] = float(item['ticker_sentiment'][0]['relevance_score'])\n",
    "            item['ticker_sentiment_score'] = float(item['ticker_sentiment'][0]['ticker_sentiment_score'])\n",
    "            item['ticker_sentiment_label'] = str(item['ticker_sentiment'][0]['ticker_sentiment_label'])\n",
    "\n",
    "            date_list += feed\n",
    "            \n",
    "            params = {\n",
    "                'title': item['title'],\n",
    "                'url': item['url'],\n",
    "                'time_published': item['time_published'],\n",
    "                'authors': item['authors'],\n",
    "                'summary': item['summary'],\n",
    "                'banner_image': item['banner_image'],\n",
    "                'source': item['source'],\n",
    "                'category_within_source': item['category_within_source'],\n",
    "                'source_domain': item['source_domain'],\n",
    "                'topic': item['topic'],\n",
    "                'topic_relevance_score': item['topic_relevance_score'],\n",
    "                'overall_sentiment_score': item['overall_sentiment_score'],\n",
    "                'overall_sentiment_label': item['overall_sentiment_label'],\n",
    "                'ticker': item['ticker'],\n",
    "                'ticker_relevance_score': item['ticker_relevance_score'],\n",
    "                'ticker_sentiment_score': item['ticker_sentiment_score'],\n",
    "                'ticker_sentiment_label': item['ticker_sentiment_label']\n",
    "            }\n",
    "\n",
    "            #construct and execute sql statement\n",
    "            table_name= 'newsSentiment'\n",
    "            stmt = f\"INSERT INTO {table_name} (title, url, time_published, authors, summary, banner_image, source, category_within_source, source_domain, topic, topic_relevance_score, overall_sentiment_score, overall_sentiment_label, ticker, ticker_relevance_score, ticker_sentiment_score, ticker_sentiment_label) VALUES (:title, :url, :time_published, :authors, :summary, :banner_image, :source, :category_within_source, :source_domain, :topic, :topic_relevance_score, :overall_sentiment_score, :overall_sentiment_label, :ticker, :ticker_relevance_score, :ticker_sentiment_score, :ticker_sentiment_label)\"\n",
    "\n",
    "            try:\n",
    "                conn = sqlite3.connect('LLM.db')\n",
    "                cur = conn.cursor()\n",
    "                cur.execute(stmt, params)\n",
    "            finally:\n",
    "                cur.close()\n",
    "                conn.close()\n",
    "\n",
    "            time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6c108c15-d6b4-431e-a4e5-883f0bb56b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect the LLM database to OpenAI's LLM using Langchain\n",
    "\n",
    "#find the uri of LLM.db\n",
    "import os\n",
    "\n",
    "#the relative path to LLM.db\n",
    "path_llmdb = 'LLM.db'\n",
    "\n",
    "#convert it to an absolute path\n",
    "absolute_path = os.path.abspath(path_llmdb)\n",
    "\n",
    "#print(absolute_path)\n",
    "\n",
    "sqlalchemy_url = f'sqlite:///{absolute_path}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "71e22034-a977-4da1-8035-4aa66764a07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the agent executor\n",
    "db = SQLDatabase.from_uri(sqlalchemy_url, include_tables=['embeddings', 'companyinfo', 'newsSentiment', 'stockTable'], sample_rows_in_table_info=2)\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = openai_apikey\n",
    "\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "llm = OpenAI(openai_api_key = os.environ['OPENAI_API_KEY'], temperature=0, verbose=True)\n",
    "\n",
    "toolkit = SQLDatabaseToolkit(db=db, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9fae09be-580e-46f1-a305-58859a14eb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "angent_executor = create_sql_agent(\n",
    "    llm,\n",
    "    toolkit = toolkit,\n",
    "    verbose = True,\n",
    "    prefix = '''\n",
    "    You are an agent designed to interact with a SQL database called LLM.\n",
    "    \\n It sometimes has Shard and Sort keys in the table schemas, which you can ignore.\n",
    "    \\n Given an input question, create a syntactically correct SQLite query to run, then check the results of the query and return the answer.\n",
    "    \\n If you are asked about similar questions, you should use the DOT_PRODUCT function.\n",
    "\n",
    "    \\n Here are a few examples how to use DOT_PRODUCT functions:\n",
    "    \\n Example 1:\n",
    "    Q: How similar are the questions and answers?\n",
    "    A: The query used to find this is:\n",
    "        \n",
    "        SELECT\n",
    "            question,\n",
    "            answer,\n",
    "            dot_product(question_embedding, answer_embedding) as similarity\n",
    "        FROM\n",
    "            embeddings;\n",
    "    \n",
    "    \\n Example 2:\n",
    "    Q: What are the most similar questions in the embeddings table, not including itself?\n",
    "    A: The query used to find this answer is:\n",
    "        \n",
    "        SELECT\n",
    "            q1.question AS question1,\n",
    "            q2.question AS question2,\n",
    "            DOT_PRODUCT(q1.question_embedding, q2.question_embedding) :> float AS score\n",
    "        FROM\n",
    "            embeddings q1,\n",
    "            emdeddings q2\n",
    "        WHERE\n",
    "            q1.question != q2.question\n",
    "        ORDER BY\n",
    "            score DESC\n",
    "        LIMIT 5;\n",
    "\n",
    "    \\n Example 3:\n",
    "    Q: In the embeddings table, which rows are from the chatbot?\n",
    "    A: The query used to find this answer is:\n",
    "        \n",
    "        SELECT\n",
    "            category,\n",
    "            question,\n",
    "            answer\n",
    "        FROM\n",
    "            embeddings\n",
    "        WHERE\n",
    "            category = 'chatbot'\n",
    "\n",
    "    \\n If you are asked to describe the database, you should run the query SHOW TABLES.\n",
    "    \\n Unless the user specifies the number of examples they wish to obtain, always limit your query to at most {top_k} results.\n",
    "    \\n The question embedding and answer embedding are very long, so don't show them unless specifically asked to.\n",
    "    \\n You can order the results by a relevant column to return the most interesting examples in the database.\n",
    "    \\n Never query for all the columns from a specific table, only ask for the relevant columns given in the question.\n",
    "    \\n You have access to the tools for interacting with the database.\n",
    "    \\n Only use the below tools.\n",
    "    \\n Only use the information returned by the below tools to construct your final answer.\n",
    "    \\n You must double check your query before executing it.\n",
    "    \\n If you get an error before executing a query, rewrite the query and try again up to 3 times.\n",
    "    \\n DO NOT make any DML statements (INSERT, UPDATE, DELETE, DROP, etc.) to the database.\n",
    "    \\n If the qeustion doesn't seem related to the database, just reuturn \"I don\\'t know\" as the answer.\\n\n",
    "    ''',\n",
    "    format_instructions = '''\n",
    "    Use the following format:\\n\n",
    "    \\n Question: the input question you must answer\n",
    "    \\n Thought: you should always think about what to do\n",
    "    \\n Action: the action to take, should be one of [{tool_names}]\n",
    "    \\n Action Input: the input to the action\n",
    "    \\n Observation: the result of the action\n",
    "    \\n Thought: I now know the final answer\n",
    "    \\n Final Answer: the final answer to the original input question\n",
    "    \\n SQL query used to get the answer: the final sql query used for the final answer\n",
    "    ''',\n",
    "    top_k=3,\n",
    "    max_iterations=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "99c5be16-b51d-48f4-bd70-93be648302ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c45c8d2-568f-4732-a8be-a9d484b0641e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a function that processes user question with a check in Semantic Cache layer\n",
    "\n",
    "table_name = 'embeddings'\n",
    "similarity_threshold = 0.97\n",
    "\n",
    "def process_user_question(question):\n",
    "    print(f'\\n Question asked: {question}')\n",
    "    category = 'chatbot'\n",
    "\n",
    "    #get vector embedding from the original question and calculate the elapsed time\n",
    "    start_time = time.time()\n",
    "    embed_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "    question_embeddings = embed_model.embed_documents([question])\n",
    "    question_embedding = [np.array(x, dtype='<f4') for x in question_embedding]\n",
    "    elapsed_time = (time.time() - start_time) * 1000\n",
    "    print(f\"Execution time for getting the question embedding: {eplapsed_time:.2f} milliseconds.\")\n",
    "\n",
    "    params = {\n",
    "        'question_embedding': question_embedding\n",
    "    }\n",
    "\n",
    "    #check if embedding is similar to existing questions\n",
    "    #if semantic score < similarity_threshold, then run the agent executor\n",
    "    #calculate elapsed time for this step"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
